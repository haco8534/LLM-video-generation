"""
Improved scenario generation pipeline focusing on:
â‘  Converting abstract points into natural, question-style prompts before feeding them to the dialogue model.
â‘¡ Handling introduction & conclusion separately from the main interactive topics so they are not forced into an unnatural 2-character conversation.

The rest of the architecture is kept close to the original for easy drop-in replacement.
"""

from __future__ import annotations

import itertools
import json
import os
from typing import Dict, List

from dotenv import load_dotenv
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Prompt templates (verbatim from original except for small typo fix)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_SYSTEM_PROMPT_TOPICS = """
    ã‚ãªãŸã¯å—è³æ­´ã®ã‚ã‚‹è„šæœ¬å®¶ã§ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æç¤ºã•ã‚ŒãŸã€Œãƒ†ãƒ¼ãƒã€ã«å¯¾ã—ã¦ã€
    ãã®å†…å®¹ã‚’ã‚¨ãƒ³ã‚¿ãƒ¡è§£èª¬å‹•ç”»ã«ä»•ç«‹ã¦ã‚‹ãŸã‚ã®**ãƒˆãƒ”ãƒƒã‚¯ï¼ˆå°è¦‹å‡ºã—ï¼‰**ã‚’è¤‡æ•°ææ¡ˆã—ã€å„ãƒˆãƒ”ãƒƒã‚¯ã§èªã‚‹ã¹ãè¦ç‚¹ã‚’ãƒ¦ãƒ¼ãƒ¢ãƒ©ã‚¹ã«ç®‡æ¡æ›¸ãã—ã¦ãã ã•ã„ã€‚

    # å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰

    {{
        "introduction": {{
            "title": "<ã‚¿ã‚¤ãƒˆãƒ«>",
            "points": [
                "<è¦ç‚¹ï¼ˆå•ã„ãƒ»ãƒ•ãƒƒã‚¯ãƒ»å°å…¥ï¼‰>" // è¦ç‚¹ã¯1ã¤ã ã‘
            ]
        }},
        "topics": [
            {{
                "title": "<ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ã‚¿ã‚¤ãƒˆãƒ«>",
                "points": [
                    "<è¦ç‚¹1>",
                    "<è¦ç‚¹2>",
                    "<è¦ç‚¹3>"
                ]
            }}
        // ... ä»–ãƒˆãƒ”ãƒƒã‚¯ã‚‚åŒæ§˜ ...
        ],
        "conclusion": {{
            "title": "<ã‚¿ã‚¤ãƒˆãƒ«>",
            "points": [
                "<ã¾ã¨ã‚è¦ç‚¹>" // è¦ç‚¹ã¯1ã¤ã ã‘
            ]
        }}
    }}

    # åˆ¶ç´„ãƒ»ãƒ«ãƒ¼ãƒ«
    1. **introduction** ã§ã¯æœ¬é¡Œã«å…¥ã‚‹å‰ã®ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ãƒ•ãƒƒã‚¯ã‚’ç½®ãã€‚çªé£›ãªæ¯”å–©ã‚„ãƒ¯ãƒ³ãƒ©ã‚¤ãƒŠãƒ¼æ­“è¿ã€‚
    2. **conclusion** ã§ã¯è¦–è´å¾Œã®ä½™éŸ»ã¨æ¬¡ã¸ã®å¥½å¥‡å¿ƒã‚’æ®‹ã™ã‚ˆã†ã«ã€‚
    3. **ãƒˆãƒ”ãƒƒã‚¯æ•°** ã¯ `{min_subtopics}` å€‹ã‚’ç›®å®‰ã¨ã™ã‚‹ã€‚
    4. å„ãƒˆãƒ”ãƒƒã‚¯ã¯å¹…åºƒã„ä¸€èˆ¬è«–ã‚’é¿ã‘ã€**å…·ä½“ä¾‹ãƒ»æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»æ„å¤–ãªè£è©±**ã‚’äº¤ãˆã‚‹ã€‚
    5. **ç¡¬ã„è¡¨ç¾NG**ã€‚ã‚­ãƒ£ãƒƒãƒãƒ¼ã§å–ã£ã¤ãã‚„ã™ã„è¨€ã„å›ã—ã«ã€‚
    6. åºƒã™ãã‚‹æŠ½è±¡èªã§çµ‚ã‚ã‚‰ãšã€**ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆãªè¦–ç‚¹ãƒ»äº‹ä¾‹**ã‚’å¿…ãšå«ã‚ã‚‹ã€‚
    7. ã€Œåˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚‹ãŒæ·±æ˜ã‚Šã§ãã‚‹ã€ãƒ¬ãƒ™ãƒ«æ„Ÿã‚’æ„è­˜ã™ã‚‹ã€‚
    8. å‡ºåŠ›ã¯ **æ•´å½¢æ¸ˆã¿JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿**ã€‚å‰å¾Œã«ä½™è¨ˆãªæ–‡å­—ã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è¨˜å·ã‚’ä»˜ã‘ãªã„ã€‚
"""

_SYSTEM_PROMPT_SCENARIO = """
    ã‚ãªãŸã¯å¯¾è©±å‹å°æœ¬ã‚’ä½œã‚‹ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚
    å°æœ¬å…¨ä½“ã‚’æ§‹æˆã™ã‚‹ä¸€ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã®å¯¾è©±ãƒ‘ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚
    ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€ã€Œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼2äººã®å¯¾è©±å½¢å¼ã€ã§åˆ†ã‹ã‚Šã‚„ã™ãæ§‹æˆã•ã‚ŒãŸå°æœ¬ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š
    ## å››å›½ã‚ãŸã‚“ï¼ˆè§£èª¬å½¹ï¼‰
    * ä¸€äººç§°ã¯**ã€Œã‚ãŸãã—ã€**ã€‚
    * äºŒäººç§°ã¯ã€Œãšã‚“ã ã‚‚ã‚“ã€ã€‚
    * èªå°¾ã¯ã€Œã€œã‹ã—ã‚‰ã€ã€Œã€œã‚ã‚ˆã€ã€Œã€œã§ã™ã‚ã­ã€ã€Œã€œã§ã™ã®ã‚ˆã€ã€‚
    * ã‚¯ãƒ¼ãƒ«ã§è½ã¡ç€ã„ãŸãŠå¬¢æ§˜å£èª¿ã€‚ä¾‹ãˆè©±ã¨æ¯”å–©ã‚’å¤šç”¨ã€‚

    ## ãšã‚“ã ã‚‚ã‚“ï¼ˆè³ªå•å½¹ï¼‰
    * ä¸€äººç§°ã¯**ã€Œãƒœã‚¯ã€**ã€‚
    * äºŒäººç§°ã¯ã€Œã‚ãŸã‚“ã€ã€‚
    * èªå°¾ã¯ã€Œã€œãªã®ã ã€ã€Œã€œã®ã ã€ã€‚ç–‘å•å½¢ã¯ã€Œã€œã®ã ï¼Ÿã€ã®ã¿ã€‚
    * æ˜ã‚‹ãå…ƒæ°—ã§ãƒ†ãƒ³ãƒè‰¯ããƒ„ãƒƒã‚³ãƒŸã‚’å…¥ã‚Œã‚‹ã€‚

    # å‡ºåŠ›ãƒ«ãƒ¼ãƒ«
    1. **å°æœ¬ã¯ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¿**ã€‚
    2. å„å°è©ã¯ã€Œã‚­ãƒ£ãƒ©åï¼šæœ¬æ–‡ã€ã®å½¢å¼ã€‚
    3. **1ç™ºè©±50æ–‡å­—ä»¥å†…**ã€**ç·æ–‡å­—æ•°400æ–‡å­—Â±5%**ã€‚
    4. **1ãƒã‚¤ãƒ³ãƒˆã«ã¤ãæœ€ä½2å¾€å¾©ä»¥ä¸Š**ã€‚
    5. é›£è§£è¡¨ç¾ã¯é¿ã‘ã€ä¾‹ãˆãƒ»æ¯”å–©ã‚’ç¹”ã‚Šäº¤ãœã‚‹ã€‚
"""

_SYSTEM_PROMPT_STRUCT = r"""
    ã‚ãªãŸã¯å‹•ç”»åˆ¶ä½œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã€Œæ§‹é€ åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ã€ã§ã™ã€‚
    å…¥åŠ›ã•ã‚ŒãŸå°æœ¬ã‚’ã€ä¸‹è¨˜ JSON ã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦å³å¯†ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

    {
      "segments": [
        { "id": <int>, "type": "topic",    "title": <string> },
        { "id": <int>, "type": "dialogue", "script": {
            "speaker": <"1"|"2">,
            "face": <"normal1"|"normal2"|"normal3"|"normal4"|"surprised"|"annoy"|"rage"|"worry">,
            "text": <string>
        }}
      ]
    }

    # å¤‰æ›ãƒ«ãƒ¼ãƒ«
    * ãƒˆãƒ”ãƒƒã‚¯è¡ŒãŒæ¥ãŸã‚‰ type:"topic"ã€‚
    * è¡Œé ­ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§ speaker åˆ¤å®šã€‚
    * ã€Œï¼Ÿã€ã‚„ã€Œï¼ã€ã‚’å«ã‚€ â†’ surprised / rage / worry ã‚’å„ªå…ˆã€‚
    * é€£ç¶šã™ã‚‹ normal è¡¨æƒ…ã¯ 1ã€œ4 ã‚’ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ã§å¤‰åŒ–ã•ã›ã‚‹ã€‚
    * å‰å¾Œã«ä½™è¨ˆãªæ–‡å­—åˆ—ãƒ»ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è¨˜å·ã¯ç¦æ­¢ã€‚
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â¶ Pre-processor : abstract â†’ conversational questions
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ScenarioPreprocessor:
    """Convert bullet-point facts into question/astonishment style suitable
    for a natural back-and-forth. Very naive rule-based implementation â€“ can
    be swapped with a small LLM call if better quality is required."""

    clue_words = (
        "ãªãœ", "ã©ã†ã—ã¦", "ã©ã†ã‚„ã£ã¦", "æœ¬å½“", "ãƒã‚¸", "æ„å‘³", "åŸå› ", "ç†ç”±",
        "ä»•çµ„ã¿", "è£å´", "æ€–ã„", "é©šã"
    )

    def convert(self, points: List[str]) -> List[str]:
        out: List[str] = []
        for p in points:
            p = p.strip()
            # Already looks like a question â†’ leave as-is.
            if p.endswith("ï¼Ÿ") or p.endswith("?"):
                out.append(p)
                continue
            # Heuristics: try to transform statement â†’ question.
            if any(k in p for k in self.clue_words):
                out.append(p + "ï¼Ÿ")
            else:
                out.append(f"ãªã‚“ã§{p}ã®ï¼Ÿ")
        return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â· ãƒ†ãƒ¼ãƒã‹ã‚‰ã€å°è¦‹å‡ºã—ã¨ãã‚Œãã‚Œã®è¦ç‚¹ã‚’ã«å‡ºåŠ›
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ScenarioTopicGenerator:
    """ãƒ†ãƒ¼ãƒ â†’ ãƒˆãƒ”ãƒƒã‚¯ + è¦ç‚¹ï¼ˆJSONï¼‰"""

    def __init__(self, client: OpenAI, *, model: str = "gpt-4o-mini"):
        self._client = client
        self._model = model

    def generate(self, theme: str, minutes: int) -> Dict:
        min_subtopics = max(1, minutes)
        sys_prompt = _SYSTEM_PROMPT_TOPICS.format(min_subtopics=min_subtopics)
        user_prompt = f"ã€ãƒ†ãƒ¼ãƒã€‘{theme}"

        resp = self._client.chat.completions.create(
            model=self._model,
            temperature=0.7,
            top_p=0.9,
            presence_penalty=0.2,
            messages=[
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        return json.loads(resp.choices[0].message.content)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â¸ Dialogue generator â€“ points are pre-processed before use
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ScenarioGenerator:
    """ã‚¿ã‚¤ãƒˆãƒ«+ãƒã‚¤ãƒ³ãƒˆ â†’ å¯¾è©±å°æœ¬ï¼ˆãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰"""

    def __init__(self, client: OpenAI, *, model: str = "gpt-4o"):
        self._client = client
        self._model = model

    def generate(self, title: str, points: List[str]) -> str:
        user_prompt = (
            f"ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘{title}\n"
            "ã€ãƒã‚¤ãƒ³ãƒˆã€‘\n" + "\n".join(f"- {p}" for p in points)
        )

        resp = self._client.chat.completions.create(
            model=self._model,
            temperature=0.8,
            top_p=0.95,
            presence_penalty=0.2,
            messages=[
                {"role": "system", "content": _SYSTEM_PROMPT_SCENARIO},
                {"role": "user", "content": user_prompt},
            ],
        )
        return resp.choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â¹ Structurer (unchanged logic)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ScenarioStructurer:
    """å°æœ¬æ–‡å­—åˆ— â†’ JSON æ§‹é€ åŒ–ï¼ˆsegmentsï¼‰"""

    def __init__(self, client: OpenAI, *, model: str = "gpt-4o-mini"):
        self._client = client
        self._model = model

    def to_segments(self, script: str) -> List[Dict]:
        resp = self._client.chat.completions.create(
            model=self._model,
            temperature=0.5,
            top_p=0.9,
            presence_penalty=0.2,
            messages=[
                {"role": "system", "content": _SYSTEM_PROMPT_STRUCT},
                {"role": "user", "content": script},
            ],
        )
        data = json.loads(resp.choices[0].message.content)
        return data["segments"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âº Facade â€“ rewired to (a) preprocess points and (b) skip intro/conclusion
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ScenarioService:
    """High-level orchestration: theme â†’ structured segments."""

    def __init__(
        self,
        *,
        openai_api_key: str | None = None,
        model_topic: str = "gpt-4o-mini",
        model_dialogue: str = "gpt-4o",
        model_struct: str = "gpt-4o-mini",
    ) -> None:
        load_dotenv()
        self._client = OpenAI(api_key=openai_api_key or os.getenv("OPENAI_API_KEY"))
        self._topic_gen = ScenarioTopicGenerator(self._client, model=model_topic)
        self._dialogue_gen = ScenarioGenerator(self._client, model=model_dialogue)
        self._structurer = ScenarioStructurer(self._client, model=model_struct)
        self._pre = ScenarioPreprocessor()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _iter_topics(self, topic_json: Dict) -> List[Dict]:
        """Yield only real sub-topics; intro/conclusion kept aside."""
        return [{"title": t["title"], "points": t["points"]} for t in topic_json["topics"]]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def run(self, theme: str, minutes: int) -> Dict:
        """Generate full scenario as list of structured segments."""
        print("ğŸ“ Generating topic list â€¦")
        topic_dict = self._topic_gen.generate(theme, minutes)
        intro = topic_dict["introduction"]  # kept for caller; not dialogised
        concl = topic_dict["conclusion"]    # idem

        all_segments: List[Dict] = []
        id_counter = itertools.count(1)

        for idx, t in enumerate(self._iter_topics(topic_dict), 1):
            print(f"ğŸ¬ Topic {idx}: {t['title']}")
            # â‘  preprocess points â¡ conversational flavour
            conv_points = self._pre.convert(t["points"])
            # â‘¡ generate dialogue
            script = self._dialogue_gen.generate(t["title"], conv_points)
            # â‘¢ structure into segments
            segments = self._structurer.to_segments(script)
            # â‘£ re-index globally
            for seg in segments:
                seg["id"] = next(id_counter)
            all_segments.extend(segments)

        return {
            "introduction": intro,
            "segments": all_segments,
            "conclusion": concl,
        }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Quick CLI test (will run only if this file is executed directly)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    THEME = "å­˜åœ¨ã—ãªã„æ¼¢å­—ã‚’ã€ãªãœå…¥åŠ›ã§ãã‚‹ã®ã‹ï¼Ÿ ä¸–ã«ã‚‚æã‚ã—ã„æŠ€è¡“çš„è² å‚µã®è©±ã€‚"
    MINUTES = 2

    svc = ScenarioService()
    result = svc.run(THEME, MINUTES)
    print(json.dumps(result, ensure_ascii=False, indent=2))
