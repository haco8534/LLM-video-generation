# main.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¤ãƒ³ãƒˆãƒ­å‹•ç”» (intro.mp4) ã¨ãƒ¡ã‚¤ãƒ³å‹•ç”» (body.mp4) ã‚’ 1 æœ¬ã«é€£çµã—ã¦
# final.mp4 ã‚’å‡ºåŠ›ã™ã‚‹æ±ºå®šç‰ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
#   1. 2 æœ¬ã‚’ **åŒä¸€ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ãƒ»åŒä¸€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿** ã¸å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
#   2. FFmpeg ã® "concat demuxer" (copy ãƒ¢ãƒ¼ãƒ‰) ã§ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³çµåˆ
#      â†’ ã©ã‚“ãªçµ„åˆã›ã§ã‚‚é•·ã• = ã‚¤ãƒ³ãƒˆãƒ­é•· + ãƒœãƒ‡ã‚£é•· ãŒä¿è¨¼ã•ã‚Œã‚‹
#   3. ä½œæ¥­ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã™ã¹ã¦å‰Šé™¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from pathlib import Path
import json
import ffmpeg  # å‹•ç”»å‡¦ç†
import tempfile
import os
from llm_video_generation.src import scenario, format
from llm_video_generation.src.intro import intro_tts, intro_video
from llm_video_generation.src.main import image, main_tts, main_video

# ===== å®šæ•° =====
THEME = "ã‚ãªãŸã¯ãªãœâ€œã¤ã„å¾Œå›ã—â€ã—ã¦ã—ã¾ã†ã®ã‹ï¼Ÿ"
VIDEO_LENGTH_MINUTES = 4

INTRO_CHAR_STYLE = {"1": "ã‚‚ã¡å­ã•ã‚“/ãƒãƒ¼ãƒãƒ«"}
MAIN_CHAR_STYLE  = {"1": "å››å›½ã‚ãŸã‚“/ãƒãƒ¼ãƒãƒ«", "2": "ãšã‚“ã ã‚‚ã‚“/ãƒãƒ¼ãƒãƒ«"}
TTS_PARAMS       = {"speedScale": 1.1, "intonationScale": 1.1}

INTRO_BGM_PATH = "llm_video_generation/assets/bgm/Mineral.mp3"
INTRO_SE_PATH  = "llm_video_generation/assets/se/5.mp3"
BODY_BGM_PATH  = "llm_video_generation/assets/bgm/Voice.mp3"
BODY_SE_PATH   = "llm_video_generation/assets/se/3.mp3"

# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====

TMP_DIR = Path(tempfile.gettempdir()) / "llm_concat_tmp"
TMP_DIR.mkdir(exist_ok=True)

def _reencode(src: Path, dst: Path) -> None:
    """src ã‚’ libx264 / aac / yuv420p / 30fps ã«æƒãˆã¦ dst ã¸å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
    (
        ffmpeg
        .input(str(src))
        .output(
            str(dst),
            vcodec="libx264",
            acodec="aac",
            pix_fmt="yuv420p",
            r=30,  # FPS ã‚’å›ºå®šã™ã‚‹ã¨ concat demuxer ãŒç¢ºå®Ÿã«å‹•ä½œ
            movflags="+faststart",
            loglevel="error",
        )
        .overwrite_output()
        .run()
    )


def concat_videos(intro_path: Path, body_path: Path, output_path: Path) -> Path:
    """ã‚¤ãƒ³ãƒˆãƒ­ â†’ ãƒœãƒ‡ã‚£ ã®é †ã§é€£çµã— output_path ã‚’è¿”ã™ã€‚

    1. ã¾ãš 2 æœ¬ã‚’ **åŒä¸€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿** ã§å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ (fast)
    2. list.txt ã‚’ä½œæˆã—ã¦ concat demuxer ã§çµåˆ (copy)
    """
    intro_path = Path(intro_path)
    body_path  = Path(body_path)

    intro_tmp = TMP_DIR / "intro_prepared.mp4"
    body_tmp  = TMP_DIR / "body_prepared.mp4"

    _reencode(intro_path, intro_tmp)
    _reencode(body_path, body_tmp)

    list_file = TMP_DIR / "list.txt"
    list_file.write_text(
        f"file '{intro_tmp.as_posix()}'\nfile '{body_tmp.as_posix()}'\n",
        encoding="utf-8",
    )

    (
        ffmpeg
        .input(str(list_file), format="concat", safe=0)
        .output(str(output_path), c="copy", movflags="+faststart", loglevel="error")
        .overwrite_output()
        .run()
    )

    # å¾Œå§‹æœ«
    for f in (intro_tmp, body_tmp, list_file):
        try:
            f.unlink()
        except FileNotFoundError:
            pass

    return output_path

# ===== å°æœ¬ç”Ÿæˆ =====

def generate_script(theme: str, minutes: int) -> dict:
    scenario_service = scenario.ScenarioBuilder(scenario.OpenAIClient())
    raw_script      = scenario_service.run(theme, minutes)
    styled_script   = format.add_design_to_topics(raw_script)
    faced_script    = format.add_random_face(styled_script)
    final_script    = format.insert_sound_info(
        faced_script,
        intro_bgm=INTRO_BGM_PATH, intro_se=INTRO_SE_PATH,
        body_bgm=BODY_BGM_PATH,  body_se=BODY_SE_PATH,
    )
    print("âœ… å°æœ¬ä½œæˆå®Œäº†")
    return final_script

# ===== ç”»åƒåé›† =====

def collect_images(script: dict) -> list[str]:
    image_service = image.ImageSetService()
    urls          = image_service.scenario_to_images(script)
    print("âœ… ç”»åƒåé›†å®Œäº†")
    return urls

# ===== ã‚¤ãƒ³ãƒˆãƒ­å‹•ç”»ç”Ÿæˆ =====

def create_intro_video(script: dict) -> Path:
    tts_pipeline  = intro_tts.IntroductionTTSPipeline(
        char_style=INTRO_CHAR_STYLE, tts_params=TTS_PARAMS, processes=3
    )
    audio_bytes   = tts_pipeline.run(script, speaker="1")
    path          = intro_video.build_intro_video(
        script, audio_bytes, output_path="intro.mp4"
    )
    print(f"âœ… ã‚¤ãƒ³ãƒˆãƒ­å‹•ç”»ç”Ÿæˆå®Œäº†: {path}")
    return Path(path)

# ===== ãƒ¡ã‚¤ãƒ³å‹•ç”»ç”Ÿæˆ =====

def create_main_video(script: dict, image_urls: list[str]) -> Path:
    tts_pipeline  = main_tts.TTSPipeline(
        char_style=MAIN_CHAR_STYLE, tts_params=TTS_PARAMS, processes=3
    )
    audio_bytes   = tts_pipeline.run(script)
    assembler     = main_video.VideoAssembler()
    path          = assembler.build_full_video(
        script, audio_bytes, image_urls, "body.mp4"
    )
    print(f"âœ… ãƒ¡ã‚¤ãƒ³å‹•ç”»ç”Ÿæˆå®Œäº†: {path}")
    return Path(path)

# ===== å®Ÿè¡Œã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ =====

def main() -> None:
    script = generate_script(THEME, VIDEO_LENGTH_MINUTES)
    
    image_urls   = collect_images(script)
    intro_path   = create_intro_video(script)
    body_path    = create_main_video(script, image_urls)

    final_path = concat_videos(intro_path, body_path, Path("final.mp4"))
    print(f"ğŸ‰ å®Œæˆå‹•ç”»: {final_path.resolve()}")

if __name__ == "__main__":
    main()
